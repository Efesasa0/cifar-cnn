{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports | Parameters | Processors | Data\n",
    "Do imports as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x106ad4b50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are set and can be changed freely. ``batchSize`` determines how much image is trained at once in the net. ``numEpochs`` determines how much training cycle is done i.e number of complete trainings of whole training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 20\n",
    "numEpochs = 3\n",
    "learnRate = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select GPU if available. M1 Mac uses ``mps``, regular nvidia uses ``cuda0``, otherwise ``cpu`` is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is set as: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available:\n",
    "    processor='mps'\n",
    "elif torch.cuda.is_available():\n",
    "    processor='cuda0'\n",
    "else:\n",
    "    processor='cpu'\n",
    "device = torch.device(device=processor)\n",
    "print(f\"device is set as: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data CIFAR10 as pytorch can do it in the code. ``Normalize`` and randomly flip the training, testing sets then convert them to ``tensors``. There are also 10 classes as shown below. \n",
    "\n",
    "Normalization of data is done with respect to mean and std and the values are retrieved from: https://stackoverflow.com/questions/66678052/how-to-calculate-the-mean-and-the-std-of-cifar10-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train data set: 35000\n",
      "Valid data set: 15000\n",
      "Test data set: 10000\n"
     ]
    }
   ],
   "source": [
    "normalized = transforms.Normalize((0.49139968, 0.48215827 ,0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
    "flip = transforms.RandomHorizontalFlip()\n",
    "crop = transforms.RandomCrop(size=32)\n",
    "\n",
    "trainValidTransform = transforms.Compose([transforms.ToTensor(), normalized, flip, crop])\n",
    "testTransform = transforms.Compose([transforms.ToTensor(), normalized])\n",
    "\n",
    "trainvalidSet = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=trainValidTransform)\n",
    "trainSet , validSet = data.random_split(trainvalidSet, [35000, 15000])\n",
    "testSet = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=testTransform)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "validLoader = torch.utils.data.DataLoader(validSet, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print('Train data set:', len(trainSet))\n",
    "print('Valid data set:', len(validSet))\n",
    "print('Test data set:', len(testSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CNN Net | Training | Testing\n",
    "The Net is defined as the class ``ConvNet`` and made as the ``model`` object. pytorch can show detailed summary for cuda0 or cpu processors but not for mps. Then for loss, ``CrossEntropyLoss`` is used since this net will clasify multiple clasess. As optimizer ``SGD`` i.e stochastic gradient descent used to optimize the parameters of the net.\n",
    "\n",
    "The following guide has been adressed in creating a CNN architecture: https://www.youtube.com/watch?v=pDdP0TFzsoQ&t=251s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32, kernel_size=3, stride=1, padding=1) # 32,32,32 \n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=3, stride=1, padding=1) #64,32,32\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0) #64,16,16\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=94, kernel_size=3, stride=1, padding=1) #94,16,16\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0) #94,8,8\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=94*8*8,out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128,out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64,out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x= F.relu(self.conv1(x))\n",
    "        x= F.relu(self.conv2(x))\n",
    "        x= self.pool1(x)\n",
    "        x= F.relu(self.conv3(x))\n",
    "        x= self.pool2(x)\n",
    "\n",
    "        x= torch.flatten(x,start_dim=1)\n",
    "        x= F.relu(self.fc1(x))\n",
    "        x= F.relu(self.fc2(x))\n",
    "        x= self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet1().to(device)\n",
    "\n",
    "if processor=='cpu' or processor=='cuda0':   \n",
    "    from torchsummary import summary\n",
    "    summary(model, (3, 32, 32))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learnRate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The net is now put into the training with pulling batches from the trainLoader. Then the inputs need to be extracted according to the device selected to benefit the specific device support.\n",
    "\n",
    "Then the net ``model`` is starting forward followed by back propagation of the error computed. The trained model is later saved to the directory of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_hist = []\n",
    "valid_loss_hist = []\n",
    "\n",
    "train_acc_hist = []\n",
    "valid_acc_hist = []\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    train_correct = 0.0\n",
    "    train_total = 0.0\n",
    "    valid_correct = 0.0\n",
    "    valid_total = 0.0\n",
    "    train_acc = 0.0\n",
    "    valid_acc = 0.0\n",
    "    model.train()\n",
    "    for i, datatrain in enumerate(iterable=trainLoader, start=0):\n",
    "        if processor == 'mps' or processor == 'cuda0': \n",
    "            inputs, labels = datatrain[0].to(device), datatrain[1].to(device)\n",
    "        else:\n",
    "            inputs, labels = datatrain\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _,pred = torch.max(outputs,1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (pred == labels).sum()\n",
    "        #print(f\"Train acc status{train_total}, {train_correct}\")\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(trainLoader)\n",
    "    train_acc = 100* train_correct / train_total\n",
    "    \n",
    "    model.eval()\n",
    "    for j, datavalid in enumerate(iterable=validLoader, start=0):\n",
    "        if processor == 'mps' or processor == 'cuda0': \n",
    "            inputs, labels = datavalid[0].to(device), datavalid[1].to(device)\n",
    "        else:\n",
    "            inputs, labels = datavalid\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _,pred = torch.max(outputs,1)\n",
    "        valid_total += labels.size(0)\n",
    "        valid_correct += (pred == labels).sum()\n",
    "        #print(f\"Valid acc status{valid_total}, {valid_correct}\")\n",
    "\n",
    "        loss=criterion(outputs,labels)\n",
    "        valid_loss+=loss.item()    \n",
    "    valid_loss = valid_loss/len(validLoader)\n",
    "    valid_acc = 100* valid_correct / valid_total\n",
    "\n",
    "\n",
    "    print(f\"For epoch: {epoch + 1} |---| trainloss={train_loss:.6f} validloss={valid_loss:.6f} | trainaccuracy={train_acc:.6f} valid={valid_acc:.6f}\") \n",
    "    train_loss_hist.append(train_loss)\n",
    "    valid_loss_hist.append(valid_loss)\n",
    "    train_acc_hist.append(train_acc.cpu().numpy())\n",
    "    valid_acc_hist.append(valid_acc.cpu().numpy())\n",
    "print('Finished Training')\n",
    "PATH = './cifar_net.v3.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss vs Validation loss with vs number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.plot(train_loss_hist, label=\"training loss\")\n",
    "plt.plot(valid_loss_hist, label=\"validation loss\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title(f'loss of training and validation vs epochs({numEpochs})')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training accuracy vs Validation accuracy with vs number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.plot(train_acc_hist, label=\"training acc\")\n",
    "plt.plot(valid_acc_hist, label=\"validation acc\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title(f'loss of training and validation vs epochs({numEpochs})')\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After The training, we now test the net ``model``. As we test the net, we disable the backpropagation and calculate the total percentage of succesfull outputs by comparing to their original label.\n",
    "\n",
    "In the same loop, we also calculate the percentage of succesfull outputs of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count=0\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        count+=1\n",
    "        #print(len(inputs), count)\n",
    "\n",
    "        outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix = np.array([[0 for i in range(10)]]*10)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    classCorrects = [0 for i in range(10)]\n",
    "    classSamples = [0 for i in range(10)]\n",
    "    for j, data in enumerate(iterable=testLoader, start=0):\n",
    "        if processor == 'mps' or processor == 'cuda0': \n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        else:\n",
    "            inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            confusionMatrix[labels[0].cpu().numpy(), predicted[0].cpu().numpy() ]+=1\n",
    "            if (label == pred):\n",
    "                classCorrects[label] += 1\n",
    "            classSamples[label] += 1\n",
    "    totalAcc=100 * correct / total\n",
    "    print(f'Accuracy of the network on the {len(testLoader)*batchSize} test images: {totalAcc} %')\n",
    "    for i in range(10):\n",
    "        classAcc = 100 * classCorrects[i] / classSamples[i]\n",
    "        print(f'Accuracy for class: {classes[i]} is {classAcc} %')\n",
    "    \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example batch of 20 images with their actual and predicted values from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainLoader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "plt.grid(False)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print('Actualval: '+' '.join(f'{classes[labels[j]]:5s} |' for j in range(batchSize)))\n",
    "\n",
    "#print predictions\n",
    "if processor == 'mps' or processor == 'cuda0': \n",
    "    outputs = model(images.to(device))\n",
    "else:\n",
    "    outputs = model(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: '+' '.join(f'{classes[predicted[j]]:5s} |' for j in range(batchSize)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix with Actual vs Predicted counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10.50, 7.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(10):\n",
    "   for j in range(10):\n",
    "      c = confusionMatrix[i, j]\n",
    "      ax.text(i, j, str(c), va='center', ha='center')\n",
    "ax.matshow(confusionMatrix, cmap=plt.cm.Blues)\n",
    "plt.xticks(range(10), classes, rotation=45)\n",
    "plt.yticks(range(10), classes, rotation=45)\n",
    "\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Training Confusion Matrix with epochs={numEpochs}')\n",
    "\n",
    "ax.grid()\n",
    "plt.rcParams[\"figure.autolayout\"] = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "491956b9afa745bf7280d65c241ec97c7dc17781bf4a8fd4fd52bdf9c510abc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
